# Google Data Analytics Capstone
My case study to complete the [Google Data Analytics Certificate](https://grow.google/certificates/data-analytics/#?modal_active=none) course. 

After months of learning exciting concepts, all of which were new for me, through the Google Data Analytics Certificate course, it's time to put my knowledge and skills to the test with a capstone project: the data analysis case study.

To accomplish this and answer the business question, I will need to follow the data analysis process: __ask, prepare, process, analyze, share,__ and __act.__ It has been a long journey but I know this is just the beginning.

# Table of Contents
1. [Scenario](#scenario)
2. [Data](#data)
3. [Ask](Pre-Analysis.md#ask)
4. [Prepare](#prepare)
5. [Process](#process)

# Bellabeat Data Analysis Case Study
![Bellabeat](https://user-images.githubusercontent.com/99853599/154403416-a370cf23-61f5-4ab3-b390-db4239df5664.PNG)
## Scenario
From the case study:
> You are a junior data analyst working on the marketing analyst team at [Bellabeat](https://bellabeat.com/), a high-tech manufacturer of health-focused products for women. You have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide marketing strategy for the company. You will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.
## Data
This data is from [Kaggle](https://www.kaggle.com/arashnic/fitbit), which contains the following description:
> These datasets were generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. Individual reports can be parsed by export session ID (column A) or timestamp (column B). Variation between output represents use of different types of Fitbit trackers and individual tracking behaviors / preferences.
## Ask 
### Guiding Questions
*What is the problem you are trying to solve?* 

Gain insight into consumer use trends of smart devices.

*How can your insights drive business decisions?*

Use the insights gained to give high-level recommendations for Bellabeat’s marketing strategy. Insights can be trends that are discovered that could identify a specific target audience that is being under-utilized or a service that needs expanding.

### Key Tasks
*1. Identify the business task*

Identify insight into consumer use trends of smart devices that will inform Bellabeat’s marketing strategy for one Bellabeat product.

*2. Consider the key stakeholders*

The key stakeholders are:
1. Urska Srsen, Bellabeat’s cofounder and Chief Creative Officer
2. Sando Mur, Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team
3. Bellabeat marketing analysis team
## Prepare
### Guiding Questions
*Where is your data stored?*

The [FitBit Fitness Tracker Data](https://www.kaggle.com/arashnic/fitbit) (CCO: Public Domain, dataset available through [Mobius](https://www.kaggle.com/arashnic)) is from Kaggle via [Zenodo](https://zenodo.org/record/53894#.Yg5oXN_MKUm). Zenodo, according to Wikipedia, is an open-access repository operated by CERN and developed under the European OpenAIRE program. I downloaded it from Kaggle in csv format.

*How is the data organized? Is it in long or wide format?*

The data is stored in long format, with one ID storing multiple instances of data.

*Are there issues with bias or credibility in this data? Does your data __ROCCC__?*

The data seems __reliable__, given its [source](https://www.kaggle.com/arashnic/fitbit). Since it is data direct from the users, it is __original__. I have validated the Kaggle set with the original source on Zenodo. The data is __comprehensive__ and should help us answer the question about trends in smart device usage. The data is not __current__, but it was the dataset we were requested to analyze. The dataset is __cited__: Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016). The data does ROCCC except for not being current. I am concerned that the sample size is too small to make any meaningful insight. Thirty is the minimum sample size, and we have a sample size of exactly thirty. Also, it looks like the users who opted to provide their data to this project chose to do so, so it is not exactly a “random” sample set, but self-selected. There is nothing in the data that would tell me whether or not the population size is unbiased in any way. I don’t know age, race, weight, gender, etc.

*How are you addressing licensing, privacy, security, and accessibility?*

The collection of this data, according to the metadata, was consented to by the Fitbit users. The data seems to have been anonymized with no readily identifiable PII (personally identifiable information). I am storing the dataset on my personal computer which is only accessible by me and can only be accessed with a password.

*How does it help you answer your question?*

Our task is to find insight into how users use the smart devices. At first glance, we have a lot of data concerning how often the device is used or tracks activity during the day, and perhaps from this we can glean insight on usage. 

*Are there any problems with the data?*

There is no metadata, so there are certain values about which I am completely confused. The sample size is smaller than ideal. Also, the data is old, from 2016. It would be best to find Fitbit data that is newer, larger, and better explained. I looked online and cannot find such a dataset.
## Process
### Guiding Questions
*What tools are you choosing and why?*

I will use SQL in BigQuery to analyze this data. The data is too large to use Excel.

*Have you ensured your data’s integrity?*

Data integrity is the accuracy, completeness, consistency, and trustworthiness of data throughout its lifecycle. I had to change the datetime data in the original files to either just date or split between date and time. I then had to give them the right format in order to upload the tables to BigQuery. Later I discovered a way to change the data type using both R and directly in BigQuery using SQL.

*What steps have you taken to ensure that your data is clean?* 

I have double-checked the data types to make sure they are accurate and will not affect any analysis that I do.

*How can you verify that your data is clean and ready to analyze?*

I made copies of the tables I cleaned so that I can compare them to the original files.

*Have you documented your cleaning process so you can review and share those results?*

Yes, I have created a changelog.

